import cv2
import numpy as np
from ultralytics import YOLO
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import load_model
import pickle
import os

# C√†i ƒë·∫∑t cho OpenCV (n·∫øu c·∫ßn d√πng RTSP)
os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;0"

class FaceRecognitionSystem:
    def __init__(self, yolo_model_path, liveness_model_path, label_encoder_path, face_detector_path, confidence=0.5):
        # Load YOLO model cho nh·∫≠n di·ªán khu√¥n m·∫∑t
        print("[INFO] loading YOLO face recognition model...")
        self.yolo_model = YOLO(yolo_model_path)
        
        # Load face detector cho liveness detection
        print("[INFO] loading face detector for liveness...")
        protoPath = os.path.sep.join([face_detector_path, "deploy.prototxt"])
        modelPath = os.path.sep.join([face_detector_path, "res10_300x300_ssd_iter_140000.caffemodel"])
        self.face_net = cv2.dnn.readNetFromCaffe(protoPath, modelPath)
        
        # Load liveness detection model
        print("[INFO] loading liveness detector...")
        self.liveness_model = load_model(liveness_model_path)
        self.le = pickle.loads(open(label_encoder_path, "rb").read())
        
        self.confidence = confidence
    
    def detect_liveness(self, frame, face_box):
        """Ph√°t hi·ªán fake/real cho khu√¥n m·∫∑t"""
        startX, startY, endX, endY = face_box
        
        # L·∫•y v√πng khu√¥n m·∫∑t
        face = frame[startY:endY, startX:endX]
        
        # Ki·ªÉm tra n·∫øu face r·ªóng
        if face.size == 0 or face.shape[0] == 0 or face.shape[1] == 0:
            return "unknown", 0.0
        
        # Preprocess ·∫£nh cho liveness detection
        face = cv2.resize(face, (64, 64))
        face = face.astype("float") / 255.0
        face = img_to_array(face)
        face = np.expand_dims(face, axis=0)
        
        # D·ª± ƒëo√°n
        preds = self.liveness_model.predict(face)[0]
        j = np.argmax(preds)
        label = self.le.classes_[j]
        confidence = preds[j]
        
        return label, confidence
    
    def process_frame(self, frame):
        """X·ª≠ l√Ω frame ƒë·ªÉ nh·∫≠n di·ªán khu√¥n m·∫∑t v√† ki·ªÉm tra liveness"""
        results = self.yolo_model(frame)
        
        # T·∫°o b·∫£n sao c·ªßa frame ƒë·ªÉ v·∫Ω k·∫øt qu·∫£
        output_frame = frame.copy()
        
        for r in results:
            boxes = r.boxes
            if boxes is not None:
                for box in boxes:
                    # L·∫•y t·ªça ƒë·ªô t·ª´ YOLO
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    yolo_confidence = box.conf[0]
                    class_id = int(box.cls[0])
                    
                    # L·∫•y t√™n ng∆∞·ªùi t·ª´ YOLO
                    person_name = r.names[class_id]
                    
                    # Ki·ªÉm tra liveness cho khu√¥n m·∫∑t n√†y
                    liveness_label, liveness_conf = self.detect_liveness(frame, (x1, y1, x2, y2))
                    
                    # X√°c ƒë·ªãnh m√†u s·∫Øc v√† th√¥ng tin hi·ªÉn th·ªã
                    if liveness_label == "fake":
                        color = (0, 0, 255)  # ƒê·ªè cho fake
                        label_text = "FAKE"  # Kh√¥ng hi·ªÉn th·ªã t√™n cho fake
                    else:
                        color = (0, 255, 0)  # Xanh cho real
                        label_text = person_name  # Hi·ªÉn th·ªã t√™n cho real
                    
                    # V·∫Ω bounding box
                    cv2.rectangle(output_frame, (x1, y1), (x2, y2), color, 2)
                    
                    # V·∫Ω th√¥ng tin
                    cv2.putText(output_frame, label_text, (x1, y1-10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        return output_frame

def main():
    # C√°c ƒë∆∞·ªùng d·∫´n model - c·∫ßn ƒëi·ªÅu ch·ªânh theo h·ªá th·ªëng c·ªßa b·∫°n
    YOLO_MODEL_PATH = "./runs/detect/train1/weights/last.pt"
    LIVENESS_MODEL_PATH = "liveness.keras"
    LABEL_ENCODER_PATH = "le.pickle"
    FACE_DETECTOR_PATH = "face_detector"
    
    # Kh·ªüi t·∫°o h·ªá th·ªëng
    try:
        system = FaceRecognitionSystem(
            yolo_model_path=YOLO_MODEL_PATH,
            liveness_model_path=LIVENESS_MODEL_PATH,
            label_encoder_path=LABEL_ENCODER_PATH,
            face_detector_path=FACE_DETECTOR_PATH,
            confidence=0.5
        )
        print("üöÄ H·ªá th·ªëng nh·∫≠n di·ªán kh·ªüi ƒë·ªông th√†nh c√¥ng!")
        print("Nh·∫•n 'q' ƒë·ªÉ tho√°t")
    except Exception as e:
        print(f"‚ùå L·ªói khi kh·ªüi t·∫°o h·ªá th·ªëng: {e}")
        return
    
    # M·ªü webcam
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        print("‚ùå Kh√¥ng th·ªÉ m·ªü webcam!")
        return
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # X·ª≠ l√Ω frame
        processed_frame = system.process_frame(frame)
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        cv2.imshow('Face Recognition & Liveness Detection', processed_frame)
        
        # Tho√°t khi nh·∫•n 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()